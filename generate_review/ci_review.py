#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ci_review.pyï¼ˆCI ç”¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰

æ¦‚è¦ï¼ˆã‚„ã‚‹ã“ã¨ï¼‰
1) PR ã§å¤‰æ›´ã•ã‚ŒãŸ docs/SRS/*.md ã‚’åé›†
2) å„ SRS ã«è¡Œç•ªå·ã‚’ä»˜ä¸ï¼ˆä¾‹: "0001â”‚ ...")
3) review_runner.py ã®ä»•æ§˜ã«åˆã‚ã›ã€repo ãƒ«ãƒ¼ãƒˆã® srs/ ã«â€œä¸€æ™‚ã‚³ãƒ”ãƒ¼â€
   â†³ review_runner.py ã¯ã€Œ--srs <ãƒ•ã‚¡ã‚¤ãƒ«å>ã€ã§ srs/ ã‚’å‚ç…§
4) review_runner.py ã‚’èµ·å‹•ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚„å‡ºåŠ›å½¢å¼ã¯ review_runner å´ã«æº–æ‹ ï¼‰
5) ç”Ÿæˆ JSON ã‚’èª­ã¿å–ã‚Šã€PR ã«ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ï¼ˆç·è©•1ä»¶ï¼‹è¡Œã‚³ãƒ¡ãƒ³ãƒˆè¤‡æ•°ï¼‰

ä½¿ã„æ–¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«æ¤œè¨¼ãƒ»CI å…±é€šã®è€ƒãˆæ–¹ï¼‰
- æ—¢å®š: review_runner.py ã® MODELS/SRS è¨­å®šã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆâ€œã‚³ãƒãƒ³ãƒ‰ã§å¿…é ˆæŒ‡å®šã—ãªã„â€æ–¹é‡ï¼‰
    python generate_review/ci_review.py
- å¿…è¦æ™‚ã ã‘ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚ä¸Šæ›¸ãï¼ˆä»»æ„ï¼‰
    python generate_review/ci_review.py --models gpt-5-mini,gpt-4.1

ç’°å¢ƒå¤‰æ•°ï¼ˆCI ã‹ã‚‰å—ã‘å–ã‚Šï¼‰
- REPO, PR_NUMBER, GITHUB_TOKENï¼ˆå¿…é ˆï¼‰

å‚™è€ƒ
- æ—¥æœ¬èªã¯ UTF-8 ã®ã¾ã¾é€ä¿¡ã€‚requests ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ UTF-8 ã‚’æ‰±ãˆã‚‹ãŸã‚è¿½åŠ è¨­å®šã¯ä¸è¦ã§ã™ã€‚
"""

from __future__ import annotations
import argparse
import json
import os
import re
import subprocess
import sys
import tempfile
import textwrap
import time
from pathlib import Path
from collections import deque
from typing import Dict, Any, List, Tuple, Optional

import difflib
import requests

# ========= åŸºæœ¬ãƒ‘ã‚¹ =========
ROOT = Path(__file__).resolve().parents[1]          # ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆ
SRS_INPUT_DIR = ROOT / "docs" / "SRS"               # å¤‰æ›´æ¤œå‡ºå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
SRS_STAGING_DIR = ROOT / "srs"                       # â˜…review_runner ãŒèª­ã‚€å ´æ‰€ï¼ˆAæ¡ˆï¼šã“ã“ã¸ä¸€æ™‚ã‚³ãƒ”ãƒ¼ï¼‰
RESULT_DIR = ROOT / "generate_review_result"         # review_runner ã®å‡ºåŠ›ç½®ãå ´
RUNNER = ROOT / "generate_review" / "review_runner.py"  # æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# ========= ãƒ­ã‚° =========
# ç›´è¿‘ãƒ­ã‚°ã®ç°¡æ˜“ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ï¼ˆå¤±æ•—é€šçŸ¥ã«è²¼ã‚‹ç”¨ï¼‰
LOG_RING: deque[str] = deque(maxlen=1000)
def info(msg: str) -> None:
    print(f"[ci_review] {msg}", flush=True)
    try:
        LOG_RING.append(f"[INFO] {msg}")
    except Exception:
        pass

def warn(msg: str) -> None:
    print(f"[ci_review][warn] {msg}", flush=True)
    try:
        LOG_RING.append(f"[WARN] {msg}")
    except Exception:
        pass

# ========= GitHub APIï¼ˆè–„ã„ãƒ©ãƒƒãƒ‘ï¼šç°¡æ˜“ãƒªãƒˆãƒ©ã‚¤ï¼‰ =========
def gh_get(url: str, token: str, params: Optional[Dict[str, Any]] = None, max_tries: int = 3):
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}
    for i in range(1, max_tries+1):
        try:
            r = requests.get(url, headers=headers, params=params or {})
            # 2xx ä»¥å¤–ã¯ raise_for_status ã§ä¾‹å¤–åŒ–
            r.raise_for_status()
            return r
        except Exception as e:
            if i == max_tries:
                raise
            warn(f"GET retry {i}/{max_tries-1} after error: {e}")
            time.sleep(1.0 * i)

def gh_post(url: str, token: str, payload: Dict[str, Any], max_tries: int = 3):
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}
    for i in range(1, max_tries+1):
        try:
            r = requests.post(url, headers=headers, json=payload)
            # 2xx ä»¥å¤–ã¯ä¾‹å¤–åŒ–ï¼ˆæœ¬æ–‡ã‚‚å‡ºã™ï¼‰
            if r.status_code >= 300:
                raise RuntimeError(f"POST {url} failed: {r.status_code} {r.text}")
            return r
        except Exception as e:
            if i == max_tries:
                raise
            warn(f"POST retry {i}/{max_tries-1} after error: {e}")
            time.sleep(1.0 * i)

# ========= PR å·®åˆ†ã‹ã‚‰ docs/SRS/*.md ã‚’å–å¾— =========
def get_changed_files(repo: str, pr_number: int, token: str) -> List[Dict[str, Any]]:
    """
    GitHub API: GET /repos/{owner}/{repo}/pulls/{pull_number}/files
    æˆ»ã‚Šå€¤ã®å„è¦ç´ ã«ã¯ filename/status/patch ãªã©ãŒå…¥ã‚‹ã€‚
    """
    url = f"https://api.github.com/repos/{repo}/pulls/{pr_number}/files"
    files = []
    page = 1
    while True:
        r = gh_get(url, token, params={"page": page, "per_page": 100})
        batch = r.json()
        files.extend(batch)
        if len(batch) < 100:
            break
        page += 1
    return files

# ========= è¡Œç•ªå·ä»˜ä¸ï¼ˆ0001â”‚ ã®ã‚ˆã†ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰ =========
def number_srs(src: Path) -> Path:
    """
    å…¥åŠ›: docs/SRS/*.md ã®å®Ÿãƒ•ã‚¡ã‚¤ãƒ«
    å‡ºåŠ›: /tmp ã«ä½œã‚‹ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¸­èº«ã¯è¡Œç•ªå·ä»˜ä¸æ¸ˆã¿ï¼‰
    """
    lines = src.read_text(encoding="utf-8").splitlines()
    numbered = "\n".join(f"{i:04d}â”‚ {line}" for i, line in enumerate(lines, 1))
    tmp = Path(tempfile.gettempdir()) / f"numbered_{src.name}"
    tmp.write_text(numbered, encoding="utf-8")
    return tmp

# ========= æ—¢å­˜ review_runner ã®èµ·å‹•ï¼ˆAæ¡ˆã®æ ¸å¿ƒï¼‰ =========
def run_review_runner_with_staged_file(staged_name: str, models_arg: Optional[str]) -> None:
    """
    review_runner.py ã¯å¾“æ¥ã©ãŠã‚Šã€Œ--srs <ãƒ•ã‚¡ã‚¤ãƒ«å>ã€ã§ srs/ ã‚’å‚ç…§ã™ã‚‹å‰æã€‚
    - staged_name ã«ã¯ SRS_STAGING_DIR ã«ç½®ã„ãŸâ€œä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«åâ€ã‚’æ¸¡ã™
    - cwd=ROOT ã§èµ·å‹•ã—ã€ç›¸å¯¾ãƒ‘ã‚¹å‚ç…§ï¼ˆinput_prompt ãªã©ï¼‰ã‚’å®‰å…¨ã«ã™ã‚‹
    """
    cmd = [sys.executable, str(RUNNER), "--srs", staged_name]
    if models_arg:
        # ä»»æ„ã€‚æŒ‡å®šãŒã‚ã‚Œã° review_runner ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰è¨­å®šã‚’ä¸Šæ›¸ãå¯èƒ½
        cmd += ["--models", models_arg]

    info("$ " + " ".join(cmd))
    # å‡ºåŠ›ã‚’æ•æ‰ã—ã¤ã¤å®Ÿè¡Œï¼ˆå¤±æ•—é€šçŸ¥ã«ãƒ­ã‚°ã‚’æ·»ä»˜ã§ãã‚‹ã‚ˆã†ã«ï¼‰
    p = subprocess.run(
        cmd,
        check=True,
        cwd=str(ROOT),
        capture_output=True,
        text=True,
    )
    if p.stdout:
        for ln in p.stdout.splitlines():
            print(ln)
            try:
                LOG_RING.append(f"[runner][out] {ln}")
            except Exception:
                pass
    if p.stderr:
        for ln in p.stderr.splitlines():
            print(ln, file=sys.stderr)
            try:
                LOG_RING.append(f"[runner][err] {ln}")
            except Exception:
                pass


# ========= ç”Ÿæˆçµæœã®èª­ã¿å–ã‚Šã¨PRã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ =========
def find_latest_json_for(stem_prefix: str) -> Optional[Path]:
    """
    generate_review_result/ ã«ä½œã‚‰ã‚ŒãŸ <stem>__<model>.json ã‚’è¦‹ã¤ã‘ã‚‹ã€‚
    è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–°ã—ã„ã‚‚ã®ã‚’æ¡ç”¨ã€‚
    """
    if not RESULT_DIR.exists():
        return None
    cands = sorted(RESULT_DIR.glob(f"{stem_prefix}__*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    return cands[0] if cands else None

def post_overall_comment(repo: str, pr_number: int, token: str, overall: str) -> None:
    url = f"https://api.github.com/repos/{repo}/issues/{pr_number}/comments"
    gh_post(url, token, {"body": overall})

def ensure_review_comment_thread(repo: str, pr_number: int, token: str) -> int:
    """
    PR ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆï¼‰ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ "EVENT_REQUEST_CHANGES" ã‚’ä½œæˆã€‚
    - GitHub API: POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews
    - æˆ»ã‚Šå€¤ JSON ã« review.id ãŒå…¥ã‚‹
    """
    url = f"https://api.github.com/repos/{repo}/pulls/{pr_number}/reviews"
    payload = {
        "body": "Auto review comments",
        "event": "REQUEST_CHANGES",  # thread ã‚’ä½œã‚‹ãŸã‚ã«ä¸€æ—¦ changes è¦æ±‚
    }
    r = gh_post(url, token, payload)
    rid = r.json().get("id")
    if not rid:
        raise RuntimeError("review.id ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
    return int(rid)

def submit_review_comments(repo: str, pr_number: int, token: str, review_id: int, comments: List[Dict[str, Any]]) -> None:
    """
    ã¾ã¨ã‚ã¦è¡Œã‚³ãƒ¡ãƒ³ãƒˆã‚’é€ä¿¡
    - GitHub API: POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments
    - payload ã¯ { comments: [ { path, position, body }, ... ] }
    """
    url = f"https://api.github.com/repos/{repo}/pulls/{pr_number}/reviews/{review_id}/comments"
    gh_post(url, token, {"comments": comments})

def find_patch_position_for_line(patch_text: str, target_line_text: str) -> Optional[int]:
    """
    GitHub ã® "position" ã¯ unified diff ä¸Šã®è¡Œç•ªå·ã€‚å¯¾è±¡ã®è¡Œãƒ†ã‚­ã‚¹ãƒˆãŒ
    unified diff ã®ã©ã“ã«ç¾ã‚Œã‚‹ã‹ã‚’æ¢ã—ã€ãã®ä½ç½®ã‚’è¿”ã™ã€‚
    - å®Œå…¨ä¸€è‡´ã§ã¯ãªãã€ä½™è¨ˆãªç©ºç™½ç­‰ã®å·®ç•°ã‚’å¸åã™ã‚‹ãŸã‚ã«è¿‘ä¼¼ãƒãƒƒãƒã‚’ä½¿ç”¨
    """
    best_pos = None
    best_ratio = 0.0
    lines = patch_text.splitlines()
    for i, ln in enumerate(lines, 1):
        ratio = difflib.SequenceMatcher(None, ln.strip(), target_line_text.strip()).ratio()
        if ratio > best_ratio:
            best_ratio = ratio
            best_pos = i
    # ã‚ã‚‹ç¨‹åº¦ä»¥ä¸Šä¼¼ã¦ã„ãªã„ã¨æ¡ç”¨ã—ãªã„
    if best_ratio < 0.6:
        return None
    return best_pos

def build_pr_review_comments_from_json(repo: str, pr_number: int, token: str, items: List[Dict[str, Any]], files_meta: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    review_items[] ã‹ã‚‰ PR è¡Œã‚³ãƒ¡ãƒ³ãƒˆï¼ˆpath/position/bodyï¼‰ã‚’æ§‹ç¯‰
    - position ã‚’æ±ºã‚ã‚‹ãŸã‚ã« PR ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã® unified diff ã‚’å‚ç…§
    """
    comments: List[Dict[str, Any]] = []

    # PR ã§å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã® filename -> patchï¼ˆunified diffï¼‰ã‚’å¼•ããŸã‚ã®è¾æ›¸
    patch_map: Dict[str, str] = {}
    for f in files_meta:
        fn = f.get("filename")
        patch = f.get("patch")
        if not fn or not patch:
            continue
        patch_map[fn] = patch

    for it in items:
        line_text = it.get("line")
        comment = it.get("comment")
        if not line_text or not comment:
            continue

        # ä»Šå›ã¯ docs/SRS/ é…ä¸‹ã—ã‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãªã„å‰æ
        # ã¾ãšå¯¾è±¡ path å€™è£œã‚’åˆ—æŒ™ï¼ˆSRS å†…ã®ä¸€ç•ªä¼¼ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»˜ã‘ã‚‹ï¼‰
        srs_paths = [p for p in patch_map.keys() if p.startswith("docs/SRS/")]
        if not srs_paths:
            continue

        best_path = None
        best_score = 0.0
        for p in srs_paths:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã® stem ãŒè¿‘ã„ã‚‚ã®ã‚’å„ªå…ˆï¼ˆç°¡æ˜“ï¼‰
            score = difflib.SequenceMatcher(None, Path(p).stem, "".join(re.findall(r"\w+", line_text.lower()))[:20]).ratio()
            if score > best_score:
                best_path = p
                best_score = score

        if not best_path:
            best_path = srs_paths[0]

        patch_text = patch_map.get(best_path, "")
        pos = find_patch_position_for_line(patch_text, line_text)
        if pos is None:
            # ä½ç½®ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€æœ€ä½é™ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡ã ã‘ã§ã‚‚æ®‹ã™ï¼ˆfall backï¼‰
            body = f"[è¡Œä½ç½®ãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ]\n\n{comment}\n\n> {line_text}"
            comments.append({"path": best_path, "position": 1, "body": body})
            continue

        body = comment
        comments.append({
            "path": best_path,
            "position": int(pos),
            "body": body,
        })

    return comments


# ========= ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼ =========
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--models", help="ä»»æ„ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚ä¸Šæ›¸ãï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚æœªæŒ‡å®šæ™‚ã¯ review_runner ã®æ—¢å®šã‚’ä½¿ç”¨ã€‚")
    args = parser.parse_args()

    repo = os.environ.get("REPO")
    pr_number = os.environ.get("PR_NUMBER")
    token = os.environ.get("GITHUB_TOKEN")
    if not repo or not pr_number or not token:
        print("REPO/PR_NUMBER/GITHUB_TOKEN ã®ç’°å¢ƒå¤‰æ•°ãŒå¿…è¦ã§ã™", file=sys.stderr)
        sys.exit(2)
    pr_number_i = int(pr_number)

    info(f"REPO={repo} PR={pr_number_i}")

    # 1) PRã®å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    files_meta = get_changed_files(repo, pr_number_i, token)
    srs_files = [f for f in files_meta if f.get("filename", "").startswith("docs/SRS/")]
    if not srs_files:
        info("docs/SRS/ é…ä¸‹ã®å¤‰æ›´ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # 2) è¡Œç•ªå·ä»˜ä¸ -> 3) srs/ ã«ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
    SRS_STAGING_DIR.mkdir(exist_ok=True)
    for f in srs_files:
        rel = f["filename"]
        src = ROOT / rel
        if not src.exists():
            warn(f"å¤‰æ›´æ¤œå‡ºã•ã‚ŒãŸãŒå®Ÿä½“ãŒãªã„: {src}")
            continue
        num = number_srs(src)
        staged_name = f"ci_numbered__{src.name}"
        dst = SRS_STAGING_DIR / staged_name
        info(f"stage: {src} -> {dst}")
        dst.write_text(num.read_text(encoding="utf-8"), encoding="utf-8")

        # 4) review_runner èµ·å‹•
        try:
            run_review_runner_with_staged_file(staged_name, args.models)
        except subprocess.CalledProcessError as e:
            warn(f"review_runner å®Ÿè¡Œã«å¤±æ•—: {e}")
            # å¤±æ•—æ™‚ã¯ãƒ­ã‚°ã‚’PRã«è²¼ã‚Šä»˜ã‘ã‚‹
            log_text = "\n".join(list(LOG_RING))
            overall = textwrap.dedent(f"""
            ğŸš¨ è‡ªå‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ
            - ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: generate_review/review_runner.py
            - ä¾‹å¤–: {e}

            <details><summary>ç›´è¿‘ãƒ­ã‚°</summary>

            ```
            {log_text}
            ```
            </details>
            """
            ).strip()
            post_overall_comment(repo, pr_number_i, token, overall)
            continue

        # 5) ç”Ÿæˆ JSON èª­ã¿å–ã‚Š -> ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
        stem_prefix = Path(staged_name).stem  # ä¾‹: ci_numbered__se24g2
        json_path = find_latest_json_for(stem_prefix)
        if not json_path or not json_path.exists():
            warn(f"çµæœ JSON ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_path}")
            continue

        data = json.loads(json_path.read_text(encoding="utf-8"))
        overall = data.get("overall")
        items = data.get("review_items", [])

        if overall:
            post_overall_comment(repo, pr_number_i, token, overall)

        if items:
            review_id = ensure_review_comment_thread(repo, pr_number_i, token)
            comments = build_pr_review_comments_from_json(repo, pr_number_i, token, items, files_meta)
            if comments:
                submit_review_comments(repo, pr_number_i, token, review_id, comments)


if __name__ == "__main__":
    main()

